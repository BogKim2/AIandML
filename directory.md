# AI and ML Coursework - Project Directory Structure

## ğŸ“ ì „ì²´ í”„ë¡œì íŠ¸ ê°œìš”

**ë¶€ì‚°ëŒ€í•™êµ ë¬¼ë¦¬í•™ê³¼ - ì „ì‚°ë¬¼ë¦¬ (2í•™ë…„ 1í•™ê¸°)**

ì´ ì €ì¥ì†ŒëŠ” AI ë° ë¨¸ì‹ ëŸ¬ë‹ ê³¼ëª©ì˜ ì‹¤ìŠµ ì½”ë“œì™€ ë¬¸ì„œë¥¼ í¬í•¨í•©ë‹ˆë‹¤.

### ğŸ‘¥ íŒ€ í”„ë¡œì íŠ¸ ì •ë³´
- **íŒ€ êµ¬ì„±**: 4ëª… 1íŒ€
- **í˜‘ì—… ë°©ì‹**: GitHubë¥¼ í†µí•œ ì½”ë“œ ê³µìœ 
- **ë°œí‘œ**: í•™ê¸°ë§ íŒ€ë³„ í”„ë¡œì íŠ¸ ë°œí‘œ ì˜ˆì •

### ì£¼ìš” ë‚´ìš© (ì£¼ì°¨ë³„ ìˆœì„œ)

**Part I: Neural Networks & Deep Learning (Weeks 1-7)**
- Week 1: ê°•ì˜ ì†Œê°œ ë° í™˜ê²½ ì„¤ì •
- Week 2: ë¨¸ì‹ ëŸ¬ë‹ ê¸°ì´ˆ
- Week 3: ì‹ ê²½ë§ ê¸°ì´ˆ
- Week 4: ë¬¼ë¦¬ ë°ì´í„°ë¡œ í•™ìŠµí•˜ê¸°
- Week 5: ë”¥ëŸ¬ë‹ í•µì‹¬ ê°œë…
- Week 6: Transformerì™€ Attention Mechanism
- Week 7: Large Language Models (LLM) ê°œë¡ 

**Part II: LLM Vibe Coding for Physics (Weeks 9-12)**
- Week 9: ê³ ì „ ì—­í•™ ì‹œë®¬ë ˆì´ì…˜
- Week 10: ì „ìê¸°í•™ ì‹œë®¬ë ˆì´ì…˜
- Week 11: ì–‘ìì—­í•™ ì‹œë®¬ë ˆì´ì…˜
- Week 12: í†µê³„ë¬¼ë¦¬ ë° Monte Carlo ì‹œë®¬ë ˆì´ì…˜

**Part III: Physics-Informed Neural Networks (Weeks 13-14)**
- Week 13: PINN ê¸°ì´ˆ ì´ë¡  (ODE í¸)
- Week 14: PINN ì‘ìš© - í¸ë¯¸ë¶„ë°©ì •ì‹

---

## ğŸ“‚ Week 1: ê°•ì˜ ì†Œê°œ ë° í™˜ê²½ ì„¤ì •

**ì£¼ì œ:** ê°œë°œ í™˜ê²½ êµ¬ì¶• ë° ì²« ë²ˆì§¸ ì‹ ê²½ë§

### íŒŒì¼ êµ¬ì¡°

```
week1/
â”œâ”€â”€ 00_hello_world.py               # Python í™˜ê²½ í…ŒìŠ¤íŠ¸
â”œâ”€â”€ 01_hello_nn.py                  # ì²« ë²ˆì§¸ Neural Network
â”œâ”€â”€ 02_polynomial_fitting.py        # ë‹¤í•­ì‹ í”¼íŒ…
â”œâ”€â”€ outputs/                        # ìƒì„±ëœ ê·¸ë˜í”„ì™€ ê²°ê³¼
â””â”€â”€ week1.md                        # í•™ìƒìš© ìƒì„¸ ë¬¸ì„œ
```

### ì£¼ìš” í•™ìŠµ ë‚´ìš©
- Python í™˜ê²½ ì„¤ì • (uv, Git, VS Code)
- AI ì½”ë”© ì–´ì‹œìŠ¤í„´íŠ¸ (Claude) ì‚¬ìš©ë²•
- ì²« ë²ˆì§¸ Neural Network êµ¬í˜„
- ë‹¤í•­ì‹ í”¼íŒ…ì„ í†µí•œ ML ê¸°ì´ˆ ì´í•´

### í•µì‹¬ ê°œë…
- Development Environment
- Neural Network ê¸°ì´ˆ
- Overfittingì˜ ê°œë…

---

## ğŸ“‚ Week 2: ë¨¸ì‹ ëŸ¬ë‹ ê¸°ì´ˆ

**ì£¼ì œ:** ì§€ë„/ë¹„ì§€ë„ í•™ìŠµê³¼ ë°ì´í„° ì „ì²˜ë¦¬

### íŒŒì¼ êµ¬ì¡°

```
week2/
â”œâ”€â”€ 01_linear_regression_spring.py  # ì„ í˜• íšŒê·€ (í›„í¬ ë²•ì¹™)
â”œâ”€â”€ 02_unsupervised_clustering.py   # ë¹„ì§€ë„ í•™ìŠµ (í´ëŸ¬ìŠ¤í„°ë§)
â”œâ”€â”€ 03_data_preprocessing.py        # ë°ì´í„° ì „ì²˜ë¦¬
â”œâ”€â”€ 04_gradient_descent_vis.py      # ê²½ì‚¬í•˜ê°•ë²• ì‹œê°í™”
â”œâ”€â”€ outputs/                        # ìƒì„±ëœ ê·¸ë˜í”„ì™€ ê²°ê³¼
â””â”€â”€ week2.md                        # í•™ìƒìš© ìƒì„¸ ë¬¸ì„œ
```

### ì£¼ìš” í•™ìŠµ ë‚´ìš©
- ì§€ë„/ë¹„ì§€ë„/ê°•í™” í•™ìŠµì˜ ì°¨ì´
- ì†ì‹¤ í•¨ìˆ˜ (Loss Function)
- Gradient Descent ì•Œê³ ë¦¬ì¦˜
- ë°ì´í„° ì •ê·œí™” ë° ì „ì²˜ë¦¬

### í•µì‹¬ ê°œë…
- Supervised/Unsupervised Learning
- Loss Functions
- Optimization
- Data Normalization

---

## ğŸ“‚ Week 3: ì‹ ê²½ë§ ê¸°ì´ˆ

**ì£¼ì œ:** Perceptronë¶€í„° MLPê¹Œì§€

### íŒŒì¼ êµ¬ì¡°

```
week3/
â”œâ”€â”€ 01_perceptron.py                # Perceptronê³¼ XOR ë¬¸ì œ
â”œâ”€â”€ 02_activation_functions.py      # í™œì„±í™” í•¨ìˆ˜ ë¹„êµ
â”œâ”€â”€ 03_forward_propagation.py       # Forward Pass
â”œâ”€â”€ 04_mlp_numpy.py                 # Multi-Layer Perceptron
â”œâ”€â”€ 05_universal_approximation.py   # Universal Approximation Theorem
â”œâ”€â”€ check_fonts.py                  # í•œê¸€ í°íŠ¸ í™•ì¸
â”œâ”€â”€ outputs/                        # ìƒì„±ëœ ê·¸ë˜í”„ì™€ ê²°ê³¼
â””â”€â”€ week3.md                        # í•™ìƒìš© ìƒì„¸ ë¬¸ì„œ
```

### ì£¼ìš” í•™ìŠµ ë‚´ìš©
- Perceptronì˜ ì›ë¦¬ì™€ í•œê³„ (XOR ë¬¸ì œ)
- Activation Functions: ReLU, Sigmoid, Tanh
- Forward Propagationì˜ ìˆ˜í•™ì  êµ¬ì¡°
- Multi-Layer Perceptron êµ¬í˜„
- Universal Approximation Theorem ì‹œì—°

### í•µì‹¬ ê°œë…
- Perceptron
- Activation Functions
- Forward Pass
- MLP Architecture

---

## ğŸ“‚ Week 4: ë¬¼ë¦¬ ë°ì´í„°ë¡œ í•™ìŠµí•˜ê¸°

**ì£¼ì œ:** Neural Networkë¥¼ ì‚¬ìš©í•œ ë¬¼ë¦¬ ë°ì´í„° í•™ìŠµ

### íŒŒì¼ êµ¬ì¡°

```
week4/
â”œâ”€â”€ 01perfect1d.py                  # 1D í•¨ìˆ˜ ê·¼ì‚¬
â”œâ”€â”€ 02projectile.py                 # í¬ë¬¼ì„  ìš´ë™ íšŒê·€
â”œâ”€â”€ 03overfitting.py                # ê³¼ì í•© vs ê³¼ì†Œì í•©
â”œâ”€â”€ 04pendulum.py                   # ì§„ì ì£¼ê¸° ì˜ˆì¸¡
â”œâ”€â”€ outputs/                        # ìƒì„±ëœ ê·¸ë˜í”„ì™€ ê²°ê³¼
â””â”€â”€ week4.md                        # í•™ìƒìš© ìƒì„¸ ë¬¸ì„œ
```

### ì£¼ìš” í•™ìŠµ ë‚´ìš©
- TensorFlow/Kerasë¥¼ ì´ìš©í•œ 1D/2D íšŒê·€
- ê³¼ì í•©(Overfitting)ê³¼ ê³¼ì†Œì í•©(Underfitting)
- ëª¨ë¸ ë³µì¡ë„ì™€ ì„±ëŠ¥ì˜ ê´€ê³„
- ë¬¼ë¦¬ ë²•ì¹™ í•™ìŠµ (ì§„ì ì£¼ê¸°)

### í•µì‹¬ ê°œë…
- Regression with Neural Networks
- Overfitting/Underfitting
- Model Complexity
- Physics Data Learning

---

## ğŸ“‚ Week 5: ë”¥ëŸ¬ë‹ í•µì‹¬ ê°œë…

**ì£¼ì œ:** Regularization, Augmentation, Transfer Learning

### íŒŒì¼ êµ¬ì¡°

```
week5/
â”œâ”€â”€ 01_regularization.py            # L1/L2, Dropout, BatchNorm
â”œâ”€â”€ 02_overfitting_underfitting.py  # ëª¨ë¸ ë³µì¡ë„ ë¶„ì„
â”œâ”€â”€ 03_data_augmentation.py         # ë°ì´í„° ì¦ê°• ê¸°ë²•
â”œâ”€â”€ 04_transfer_learning.py         # ì „ì´ í•™ìŠµ
â”œâ”€â”€ 05_mnist_cnn.py                 # MNIST CNN ì‹¤ìŠµ
â”œâ”€â”€ outputs/                        # ìƒì„±ëœ ê·¸ë˜í”„ì™€ ê²°ê³¼
â””â”€â”€ week5.md                        # í•™ìƒìš© ìƒì„¸ ë¬¸ì„œ
```

### ì£¼ìš” í•™ìŠµ ë‚´ìš©
- Regularization ê¸°ë²•: L1/L2, Dropout, Batch Normalization
- Data Augmentationìœ¼ë¡œ ë°ì´í„° ë¶€ì¡± í•´ê²°
- Transfer Learning ê°œë…ê³¼ í™œìš©
- CNNì„ ì´ìš©í•œ MNIST ì†ê¸€ì”¨ ì¸ì‹

### í•µì‹¬ ê°œë…
- Regularization
- Data Augmentation
- Transfer Learning
- CNN Basics

---

## ğŸ“‚ Week 6: Transformerì™€ Attention Mechanism

**ì£¼ì œ:** RNNì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ëŠ” Transformer ì•„í‚¤í…ì²˜

### íŒŒì¼ êµ¬ì¡°

```
week6/
â”œâ”€â”€ 01_attention_basics.py          # Attention ë©”ì»¤ë‹ˆì¦˜ ê¸°ì´ˆ
â”œâ”€â”€ 02_self_attention.py            # Self-Attentionê³¼ Multi-Head
â”œâ”€â”€ 03_positional_encoding.py       # ìœ„ì¹˜ ì¸ì½”ë”©
â”œâ”€â”€ 04_transformer_block.py         # ì™„ì „í•œ Transformer Block
â”œâ”€â”€ 05_sequence_modeling.py         # ì‹¤ì „ ì‹œí€€ìŠ¤ ëª¨ë¸ë§
â”œâ”€â”€ outputs/                        # ìƒì„±ëœ ê·¸ë˜í”„ì™€ ê²°ê³¼
â”œâ”€â”€ week6.md                        # í•™ìƒìš© ìƒì„¸ ë¬¸ì„œ
â””â”€â”€ run.bat                         # ìë™ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
```

### ì£¼ìš” í•™ìŠµ ë‚´ìš©
- Attention ë©”ì»¤ë‹ˆì¦˜ì˜ ì›ë¦¬ (Query, Key, Value)
- Self-Attentionê³¼ Multi-Head Attention
- Positional Encodingì˜ í•„ìš”ì„±
- ì™„ì „í•œ Transformer Encoder Block êµ¬í˜„
- ì‹¤ì œ ì‹œí€€ìŠ¤ ì˜ˆì¸¡ ë¬¸ì œ ì ìš©

### í•µì‹¬ ê°œë…
- Attention Mechanism
- Self-Attention
- Multi-Head Attention
- Positional Encoding
- Transformer Architecture

**ì°¸ê³  ë…¼ë¬¸:** "Attention Is All You Need" (Vaswani et al., 2017)

---

## ğŸ“‚ Week 7: Large Language Models (LLM) ê°œë¡ 

**ì£¼ì œ:** GPT, BERT, Claude - LLMì˜ ì´í•´ì™€ í™œìš©

### íŒŒì¼ êµ¬ì¡°

```
week7/
â”œâ”€â”€ 01_tokens_and_embeddings.py     # Tokenê³¼ Embedding ê¸°ì´ˆ
â”œâ”€â”€ 02_gpt_bert_architectures.py    # GPT vs BERT ì•„í‚¤í…ì²˜
â”œâ”€â”€ 03_pretraining_finetuning.py    # Pre-trainingê³¼ Fine-tuning
â”œâ”€â”€ 04_claude_api_simple.py         # Claude API ê°œë… (ì‹œë®¬ë ˆì´ì…˜)
â”œâ”€â”€ outputs/                        # ìƒì„±ëœ ê·¸ë˜í”„ì™€ ê²°ê³¼
â”œâ”€â”€ week7.md                        # í•™ìƒìš© ìƒì„¸ ë¬¸ì„œ
â””â”€â”€ run.bat                         # ìë™ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
```

### ì£¼ìš” í•™ìŠµ ë‚´ìš©
- Tokenization: Character, Word, BPE
- Token Embeddingê³¼ Context Window
- GPT (Decoder-only) vs BERT (Encoder-only)
- Pre-training, Fine-tuning, RLHF
- LLM API ì‚¬ìš©ë²• (Claude API ì‹œë®¬ë ˆì´ì…˜)

### í•µì‹¬ ê°œë…
- Tokenization
- Embeddings
- GPT vs BERT
- Pre-training/Fine-tuning
- RLHF
- Prompt Engineering

**ì°¸ê³  ë…¼ë¬¸:**
- "BERT" (Devlin et al., 2018)
- "GPT-3" (Brown et al., 2020)

---

## ğŸ“‚ Week 9: ê³ ì „ ì—­í•™ ì‹œë®¬ë ˆì´ì…˜

**ì£¼ì œ:** ìˆ˜ì¹˜ ì ë¶„ê³¼ í˜¼ëˆ ì‹œìŠ¤í…œ

### íŒŒì¼ êµ¬ì¡°

```
week9/
â”œâ”€â”€ 01euler_rk4.py                  # Euler vs RK4 ë¹„êµ
â”œâ”€â”€ 02planetary.py                  # í–‰ì„± ìš´ë™ ì‹œë®¬ë ˆì´ì…˜
â”œâ”€â”€ 03chaotic_pendulum.py           # í˜¼ëˆ ì§„ì
â”œâ”€â”€ 04lagrangian_hamiltonian.py     # ë¼ê·¸ë‘ì§€ì•ˆ/í•´ë°€í† ë‹ˆì•ˆ
â”œâ”€â”€ outputs/                        # ìƒì„±ëœ ê·¸ë˜í”„ì™€ ê²°ê³¼
â””â”€â”€ week9.md                        # í•™ìƒìš© ìƒì„¸ ë¬¸ì„œ
```

### ì£¼ìš” í•™ìŠµ ë‚´ìš©
- ìˆ˜ì¹˜ ì ë¶„ ë°©ë²• (Euler, RK4)
- í–‰ì„± ìš´ë™ê³¼ ì¼€í”ŒëŸ¬ ë²•ì¹™
- í˜¼ëˆ ì‹œìŠ¤í…œ (ì´ì¤‘ ì§„ì)
- ë¼ê·¸ë‘ì§€ì•ˆê³¼ í•´ë°€í† ë‹ˆì•ˆ ì—­í•™

### í•µì‹¬ ê°œë…
- Numerical Integration
- ODEs
- Chaotic Systems
- Lagrangian/Hamiltonian Mechanics

---

## ğŸ“‚ Week 10: ì „ìê¸°í•™ ì‹œë®¬ë ˆì´ì…˜

**ì£¼ì œ:** Maxwell ë°©ì •ì‹ê³¼ ì „ìê¸°íŒŒ

### íŒŒì¼ êµ¬ì¡°

```
week10/
â”œâ”€â”€ 01_electric_field_basics.py     # ì „ê¸°ì¥ ê¸°ì´ˆ
â”œâ”€â”€ 02_electric_potential.py        # ì „ìœ„ ê³„ì‚°
â”œâ”€â”€ 03_electric_field_lines.py      # ì „ê¸°ë ¥ì„ 
â”œâ”€â”€ 04_magnetic_field_basics.py     # ìê¸°ì¥ ê¸°ì´ˆ
â”œâ”€â”€ 05_lorentz_force.py             # ë¡œë Œì¸  í˜
â”œâ”€â”€ 06_maxwell_1d.py                # Maxwell ë°©ì •ì‹ 1D
â”œâ”€â”€ 07_maxwell_2d.py                # Maxwell ë°©ì •ì‹ 2D
â”œâ”€â”€ 08_multiple_charges.py          # ë‹¤ì¤‘ ì „í•˜
â”œâ”€â”€ 09_em_wave_animation.py         # ì „ìê¸°íŒŒ ì• ë‹ˆë©”ì´ì…˜
â”œâ”€â”€ 10_conductor_potential.py       # ë„ì²´ ì „ìœ„
â”œâ”€â”€ outputs/                        # ìƒì„±ëœ ê·¸ë˜í”„ì™€ ê²°ê³¼
â””â”€â”€ week10.md                       # í•™ìƒìš© ìƒì„¸ ë¬¸ì„œ
```

### ì£¼ìš” í•™ìŠµ ë‚´ìš©
- ì „ê¸°ì¥ê³¼ ìê¸°ì¥ ê³„ì‚° ë° ì‹œê°í™”
- Maxwell ë°©ì •ì‹ì˜ ìˆ˜ì¹˜ í•´ë²• (FDTD)
- ë¼í”Œë¼ìŠ¤ ë°©ì •ì‹ê³¼ ì •ì „ê¸° ë¬¸ì œ
- ì „ìê¸°íŒŒ ì „íŒŒ ì‹œë®¬ë ˆì´ì…˜

### í•µì‹¬ ê°œë…
- Electric/Magnetic Fields
- Maxwell Equations
- FDTD (Finite Difference Time Domain)
- Electromagnetic Waves

---

## ğŸ“‚ Week 11: ì–‘ìì—­í•™ ì‹œë®¬ë ˆì´ì…˜

**ì£¼ì œ:** SchrÃ¶dinger ë°©ì •ì‹ê³¼ ì–‘ì í˜„ìƒ

### íŒŒì¼ êµ¬ì¡°

```
week11/
â”œâ”€â”€ 01schrodinger.py                # SchrÃ¶dinger ë°©ì •ì‹ ê¸°ì´ˆ
â”œâ”€â”€ 02wavefunction.py               # íŒŒë™í•¨ìˆ˜ ì‹œê°í™”
â”œâ”€â”€ 03tunneling.py                  # í„°ë„ë§ íš¨ê³¼
â”œâ”€â”€ 04wells_oscillator.py           # ì–‘ì ìš°ë¬¼ê³¼ ì¡°í™” ì§„ë™ì
â”œâ”€â”€ outputs/                        # ìƒì„±ëœ ê·¸ë˜í”„ì™€ ê²°ê³¼
â””â”€â”€ week11.md                       # í•™ìƒìš© ìƒì„¸ ë¬¸ì„œ
```

### ì£¼ìš” í•™ìŠµ ë‚´ìš©
- SchrÃ¶dinger ë°©ì •ì‹ì˜ ìˆ˜ì¹˜ í•´ë²•
- íŒŒë™í•¨ìˆ˜ì™€ í™•ë¥  í•´ì„
- í„°ë„ë§ íš¨ê³¼ ì‹œë®¬ë ˆì´ì…˜
- Finite Well, Harmonic Oscillator

### í•µì‹¬ ê°œë…
- SchrÃ¶dinger Equation
- Wave Functions
- Quantum Tunneling
- Potential Wells
- Quantum Harmonic Oscillator

---

## ğŸ“‚ Week 12: í†µê³„ë¬¼ë¦¬ ë° Monte Carlo ì‹œë®¬ë ˆì´ì…˜

**ì£¼ì œ:** Monte Carlo ë°©ë²•ê³¼ 2D Ising Model

### íŒŒì¼ êµ¬ì¡°

```
week12/
â”œâ”€â”€ 01_random_walk.py               # Random Walk ì‹œë®¬ë ˆì´ì…˜
â”œâ”€â”€ 02_pi_estimation.py             # Monte Carloë¡œ Ï€ ì¶”ì •
â”œâ”€â”€ 03_ising_1d.py                  # 1D Ising Model
â”œâ”€â”€ 04_metropolis.py                # Metropolis ì•Œê³ ë¦¬ì¦˜
â”œâ”€â”€ 05_ising_2d_basic.py            # 2D Ising Model ê¸°ì´ˆ
â”œâ”€â”€ 06_phase_transition.py          # ìƒì „ì´ ë¶„ì„
â”œâ”€â”€ 07_thermodynamics.py            # ì—´ì—­í•™ì  ì„±ì§ˆ
â”œâ”€â”€ 08_ising_2d_advanced.py         # ê³ ê¸‰ ë¶„ì„
â”œâ”€â”€ outputs/                        # ìƒì„±ëœ ê·¸ë˜í”„ì™€ ê²°ê³¼
â””â”€â”€ week12.md                       # í•™ìƒìš© ìƒì„¸ ë¬¸ì„œ
```

### ì£¼ìš” í•™ìŠµ ë‚´ìš©
- Monte Carlo ë°©ë²•ë¡ 
- Random Walkì™€ í†µê³„ì  ì„±ì§ˆ
- Ising ëª¨ë¸ê³¼ ìƒì „ì´
- Metropolis-Hastings ì•Œê³ ë¦¬ì¦˜
- ì—´ì—­í•™ì  ì„±ì§ˆ ê³„ì‚° (ì—ë„ˆì§€, ë¹„ì—´, ìí™”ìœ¨)

### í•µì‹¬ ê°œë…
- Monte Carlo Methods
- Random Walk
- Ising Model
- Metropolis Algorithm
- Phase Transitions
- Statistical Physics

**ì°¸ê³  êµì¬:**
- "Statistical Mechanics" (Pathria)
- "Monte Carlo Methods" (Landau & Binder)

---

## ğŸ“‚ Week 13: PINN ê¸°ì´ˆ ì´ë¡  (ODE í¸)

**ì£¼ì œ:** Physics-Informed Neural Networksë¡œ ODE í’€ê¸°

### íŒŒì¼ êµ¬ì¡°

```
week13/
â”œâ”€â”€ 01_simple_ode.py                # ë‹¨ìˆœ ODE (TensorFlow)
â”œâ”€â”€ 02_harmonic_oscillator.py       # ì¡°í™” ì§„ë™ì (PyTorch)
â”œâ”€â”€ 03_damped_oscillator.py         # ê°ì‡  ì§„ë™ì (TensorFlow)
â”œâ”€â”€ 04_boundary_value_problem.py    # ê²½ê³„ê°’ ë¬¸ì œ (PyTorch)
â”œâ”€â”€ 05_lorenz_system.py             # ë¡œë Œì¸  ì‹œìŠ¤í…œ (í˜¼ëˆ ì—­í•™)
â”œâ”€â”€ 06_comparison_frameworks.py     # TensorFlow vs PyTorch ë¹„êµ
â”œâ”€â”€ outputs/                        # ìƒì„±ëœ ê·¸ë˜í”„ì™€ ê²°ê³¼
â”œâ”€â”€ week13.md                       # í•™ìƒìš© ìƒì„¸ ë¬¸ì„œ
â””â”€â”€ README.md                       # ì‹¤í–‰ ê°€ì´ë“œ
```

### ì£¼ìš” í•™ìŠµ ë‚´ìš©
- PINNì˜ ê¸°ë³¸ ê°œë…ê³¼ ì‘ë™ ì›ë¦¬
- ë¬¼ë¦¬ ë²•ì¹™ì„ Loss Functionì— í¬í•¨í•˜ê¸°
- Automatic Differentiation
- TensorFlowì™€ PyTorchë¡œ PINN êµ¬í˜„
- ODE ë¬¸ì œì— PINN ì ìš©
- ì „í†µì ì¸ ìˆ˜ì¹˜ í•´ë²•(RK4)ê³¼ ë¹„êµ

### í•µì‹¬ ê°œë…
- Physics-Informed Neural Networks
- Physics Loss
- Automatic Differentiation
- Boundary Conditions
- TensorFlow vs PyTorch

**ì°¸ê³  ë…¼ë¬¸:**
- Raissi et al., "Physics-informed neural networks" (2019)
- Karniadakis et al., "Physics-informed machine learning" (2021)

---

## ğŸ“‚ Week 14: PINN ì‘ìš© - í¸ë¯¸ë¶„ë°©ì •ì‹

**ì£¼ì œ:** PINNìœ¼ë¡œ PDE í’€ê¸°

### íŒŒì¼ êµ¬ì¡°

```
week14/
â”œâ”€â”€ 01_basic_pinn.py                # PINN ê¸°ë³¸ êµ¬ì¡°
â”œâ”€â”€ 02_heat_equation_1d.py          # 1D ì—´ì „ë„ ë°©ì •ì‹
â”œâ”€â”€ 03_wave_equation_1d.py          # 1D íŒŒë™ ë°©ì •ì‹
â”œâ”€â”€ 04_heat_equation_2d.py          # 2D ì—´ì „ë„ ë°©ì •ì‹
â”œâ”€â”€ 05_burgers_equation.py          # Burgers ë°©ì •ì‹ (ë¹„ì„ í˜•)
â”œâ”€â”€ 06_wave_equation_2d.py          # 2D íŒŒë™ ë°©ì •ì‹
â”œâ”€â”€ 07_complex_boundary.py          # ë³µì¡í•œ ê²½ê³„ì¡°ê±´
â”œâ”€â”€ run_all.py                      # ëª¨ë“  ìŠ¤í¬ë¦½íŠ¸ ìë™ ì‹¤í–‰
â”œâ”€â”€ outputs/                        # ìƒì„±ëœ ê·¸ë˜í”„ì™€ ê²°ê³¼
â”œâ”€â”€ week14.md                       # í•™ìƒìš© ìƒì„¸ ë¬¸ì„œ
â””â”€â”€ RUN_ALL.md                      # ì‹¤í–‰ ê°€ì´ë“œ
```

### ì£¼ìš” í•™ìŠµ ë‚´ìš©
- 1D/2D Heat Equation (ì—´ì „ë„ ë°©ì •ì‹)
- 1D/2D Wave Equation (íŒŒë™ ë°©ì •ì‹)
- Burgers Equation (ë¹„ì„ í˜• PDE)
- ë³µì¡í•œ ê²½ê³„ì¡°ê±´ ì²˜ë¦¬
- PINNì˜ ì¥ë‹¨ì  ë¶„ì„

### í•µì‹¬ ê°œë…
- Partial Differential Equations (PDEs)
- Heat Equation
- Wave Equation
- Burgers Equation
- Boundary Conditions
- PINN for Spatial-Temporal Problems

**ì°¸ê³  ë…¼ë¬¸:**
- Raissi et al., "Physics-informed neural networks" (2019)
- Cuomo et al., "Scientific Machine Learning" (2022)

---

## ğŸ”§ ê³µí†µ ì„¤ì • ë° ê·œì¹™

### .cursorrules íŒŒì¼

ëª¨ë“  Python ì½”ë“œëŠ” ë‹¤ìŒ ê·œì¹™ì„ ë”°ë¦…ë‹ˆë‹¤:

**1. í•œê¸€ í°íŠ¸ ì„¤ì •:**
```python
def set_korean_font():
    font_list = [f.name for f in fm.fontManager.ttflist]
    if 'Malgun Gothic' in font_list:
        plt.rcParams['font.family'] = 'Malgun Gothic'
    elif 'Gulim' in font_list:
        plt.rcParams['font.family'] = 'Gulim'
    elif 'Batang' in font_list:
        plt.rcParams['font.family'] = 'Batang'
    elif 'AppleGothic' in font_list:
        plt.rcParams['font.family'] = 'AppleGothic'
    plt.rcParams['axes.unicode_minus'] = False
```

**2. Weight ì´ˆê¸°í™” (ì‹ ê²½ë§):**
```python
# Xavier/Glorot for Sigmoid/Tanh
limit = np.sqrt(6 / (n_in + n_out))
W = np.random.uniform(-limit, limit, (n_in, n_out))

# He for ReLU
std = np.sqrt(2 / n_in)
W = np.random.randn(n_in, n_out) * std
```

**3. Scatter Plot:**
```python
# Unfilled markers (x, +): edgecolors ì‚¬ìš© X
ax.scatter(..., marker='x', c='red')

# Filled markers (o, s): edgecolors ì‚¬ìš© ê°€ëŠ¥
ax.scatter(..., marker='o', c='red', edgecolors='black')
```

---

## ğŸ“Š í”„ë¡œì íŠ¸ ë¹„êµ

### ì£¼ì°¨ë³„ ë‚œì´ë„ ë° íŠ¹ì§•

| Week | ì£¼ì œ | ë‚œì´ë„ | í•µì‹¬ ê¸°ìˆ  | ì‘ìš© ë¶„ì•¼ |
|------|------|--------|----------|----------|
| 1 | í™˜ê²½ ì„¤ì • | â­ | Python, Git | ê¸°ì´ˆ |
| 2 | ML ê¸°ì´ˆ | â­â­ | Regression, Clustering | ë°ì´í„° ë¶„ì„ |
| 3 | ì‹ ê²½ë§ ê¸°ì´ˆ | â­â­ | Perceptron, MLP | ë¶„ë¥˜ |
| 4 | ë¬¼ë¦¬ í•™ìŠµ | â­â­â­ | TensorFlow/Keras | íšŒê·€ |
| 5 | ë”¥ëŸ¬ë‹ ê¸°ë²• | â­â­â­ | Regularization, CNN | ì´ë¯¸ì§€ |
| 6 | Transformer | â­â­â­â­ | Attention, Self-Attention | NLP |
| 7 | LLM | â­â­â­ | GPT, BERT | ì–¸ì–´ ëª¨ë¸ |
| 9 | ê³ ì „ ì—­í•™ | â­â­â­ | ODE, RK4 | ì‹œë®¬ë ˆì´ì…˜ |
| 10 | ì „ìê¸°í•™ | â­â­â­â­ | PDE, FDTD | íŒŒë™ |
| 11 | ì–‘ìì—­í•™ | â­â­â­â­ | SchrÃ¶dinger | ì–‘ì |
| 12 | í†µê³„ë¬¼ë¦¬ | â­â­â­â­ | Monte Carlo, Ising | ìƒì „ì´ |
| 13 | PINN ODE | â­â­â­â­â­ | PINN, ODE | AI+ë¬¼ë¦¬ |
| 14 | PINN PDE | â­â­â­â­â­ | PINN, PDE | AI+ë¬¼ë¦¬ |

### í”„ë ˆì„ì›Œí¬ ì‚¬ìš© í˜„í™©

- **Pure Numpy**: Week 1-3, 6 (ê¸°ì´ˆ ì´ë¡ )
- **TensorFlow/Keras**: Week 4-5 (ë”¥ëŸ¬ë‹ ê¸°ì´ˆ)
- **Matplotlib**: Week 1-14 (ì‹œê°í™”)
- **SciPy**: Week 9-11 (ìˆ˜ì¹˜ í•´ë²•)
- **TensorFlow/PyTorch**: Week 13-14 (PINN)

---

## ğŸ’» ì‹¤í–‰ ë°©ë²•

### ê¸°ë³¸ ì‹¤í–‰ (ëª¨ë“  ì£¼ì°¨ ê³µí†µ)

```bash
# í•´ë‹¹ ì£¼ì°¨ ë””ë ‰í† ë¦¬ë¡œ ì´ë™
cd week1

# ìˆœì„œëŒ€ë¡œ ì‹¤í–‰
uv run python 01_íŒŒì¼ëª….py
uv run python 02_íŒŒì¼ëª….py
...

# ê²°ê³¼ í™•ì¸
ls outputs/
```

### ìë™ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ (Week 6, 7)

```bash
# Week 6 ë˜ëŠ” Week 7 ë””ë ‰í† ë¦¬ë¡œ ì´ë™
cd week6

# run.bat ì‹¤í–‰ (Windows)
./run.bat

# ëª¨ë“  Python íŒŒì¼ì´ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰ë˜ê³  ì—ëŸ¬ ì‹œ ìë™ ì¤‘ë‹¨
```

### Week 14 ì „ì²´ ì‹¤í–‰

```bash
cd week14

# ëª¨ë“  PINN ì‹¤ìŠµ í•œë²ˆì— ì‹¤í–‰
uv run python run_all.py
```

---

## ğŸ“š í•™ìŠµ ìˆœì„œ ì¶”ì²œ

### ì´ˆê¸‰ ê³¼ì • (Week 1-5)

1. **Week 1**: í™˜ê²½ ì„¤ì • ë° ì²« NN
2. **Week 2**: ML ê¸°ë³¸ ê°œë…
3. **Week 3**: ì‹ ê²½ë§ ì´ë¡ 
4. **Week 4**: ë¬¼ë¦¬ ë°ì´í„° í•™ìŠµ
5. **Week 5**: ë”¥ëŸ¬ë‹ ê¸°ë²•

ğŸ‘‰ **ëª©í‘œ**: Neural Networkì˜ ê¸°ë³¸ ì›ë¦¬ ì´í•´

### ì¤‘ê¸‰ ê³¼ì • (Week 6-7, 9-11)

1. **Week 6**: Transformer ì•„í‚¤í…ì²˜
2. **Week 7**: LLM ê°œë¡ 
3. **Week 9**: ê³ ì „ ì—­í•™ ì‹œë®¬ë ˆì´ì…˜
4. **Week 10**: ì „ìê¸°í•™ ì‹œë®¬ë ˆì´ì…˜
5. **Week 11**: ì–‘ìì—­í•™ ì‹œë®¬ë ˆì´ì…˜

ğŸ‘‰ **ëª©í‘œ**: ë”¥ëŸ¬ë‹ê³¼ ë¬¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ëŠ¥ë ¥

### ê³ ê¸‰ ê³¼ì • (Week 12-14)

1. **Week 12**: Monte Carloì™€ í†µê³„ë¬¼ë¦¬
2. **Week 13**: PINN ê¸°ì´ˆ (ODE)
3. **Week 14**: PINN ì‘ìš© (PDE)

ğŸ‘‰ **ëª©í‘œ**: AIì™€ ë¬¼ë¦¬ì˜ ìœµí•© (PINN)

---

## ğŸ¯ í•™ìŠµ ëª©í‘œ ë‹¬ì„± ì²´í¬ë¦¬ìŠ¤íŠ¸

### Part I: Neural Networks & Deep Learning

**ê¸°ë³¸:**
- [ ] Python í™˜ê²½ ì„¤ì • ì™„ë£Œ
- [ ] Neural Network ì‘ë™ ì›ë¦¬ ì´í•´
- [ ] Loss Functionê³¼ Optimization ì´í•´
- [ ] Activation Functionsì˜ ì—­í•  ì„¤ëª… ê°€ëŠ¥

**ì¤‘ê¸‰:**
- [ ] Backpropagation ì•Œê³ ë¦¬ì¦˜ ì´í•´
- [ ] Overfitting ë°©ì§€ ê¸°ë²• ì ìš© ê°€ëŠ¥
- [ ] CNNìœ¼ë¡œ ì´ë¯¸ì§€ ë¶„ë¥˜ ê°€ëŠ¥
- [ ] Transformerì˜ Attention ë©”ì»¤ë‹ˆì¦˜ ì´í•´

**ê³ ê¸‰:**
- [ ] LLMì˜ ì•„í‚¤í…ì²˜ ë¹„êµ ê°€ëŠ¥
- [ ] Prompt Engineering í™œìš© ê°€ëŠ¥
- [ ] Transfer Learning ì ìš© ê°€ëŠ¥

### Part II: LLM Vibe Coding for Physics

**ê¸°ë³¸:**
- [ ] ODE ìˆ˜ì¹˜ í•´ë²• (Euler, RK4) êµ¬í˜„
- [ ] ì „ê¸°ì¥/ìê¸°ì¥ ê³„ì‚° ê°€ëŠ¥
- [ ] SchrÃ¶dinger ë°©ì •ì‹ ê¸°ì´ˆ ì´í•´
- [ ] Monte Carlo ì›ë¦¬ ì´í•´

**ì¤‘ê¸‰:**
- [ ] í˜¼ëˆ ì‹œìŠ¤í…œ ì‹œë®¬ë ˆì´ì…˜
- [ ] Maxwell ë°©ì •ì‹ ìˆ˜ì¹˜ í•´ë²•
- [ ] ì–‘ì í„°ë„ë§ ì‹œë®¬ë ˆì´ì…˜
- [ ] Metropolis ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„

**ê³ ê¸‰:**
- [ ] ë¼ê·¸ë‘ì§€ì•ˆ/í•´ë°€í† ë‹ˆì•ˆ ì—­í•™ í™œìš©
- [ ] FDTDë¡œ ì „ìê¸°íŒŒ ì‹œë®¬ë ˆì´ì…˜
- [ ] ì–‘ì ì¡°í™” ì§„ë™ì ë¶„ì„
- [ ] 2D Ising ëª¨ë¸ ìƒì „ì´ ë¶„ì„

### Part III: Physics-Informed Neural Networks

**ê¸°ë³¸:**
- [ ] PINNì˜ ê¸°ë³¸ ê°œë… ì´í•´
- [ ] Physics Loss êµ¬ì„± ë°©ë²• ì´í•´
- [ ] Automatic Differentiation í™œìš©

**ì¤‘ê¸‰:**
- [ ] ODE ë¬¸ì œë¥¼ PINNìœ¼ë¡œ í•´ê²°
- [ ] TensorFlowì™€ PyTorchë¡œ PINN êµ¬í˜„
- [ ] ê²½ê³„ì¡°ê±´ ì²˜ë¦¬ ë°©ë²• ì´í•´

**ê³ ê¸‰:**
- [ ] PDE ë¬¸ì œë¥¼ PINNìœ¼ë¡œ í•´ê²°
- [ ] ë³µì¡í•œ ê²½ê³„ì¡°ê±´ ì²˜ë¦¬
- [ ] PINNê³¼ ì „í†µì  ë°©ë²• ë¹„êµ ë¶„ì„
- [ ] ì‹¤ì œ ë¬¼ë¦¬ ë¬¸ì œì— PINN ì ìš©

---

## ğŸ”— ê´€ë ¨ ìë£Œ

### í•„ìˆ˜ ë…¼ë¬¸

**Transformers & LLM:**
- "Attention Is All You Need" (Vaswani et al., 2017)
- "BERT" (Devlin et al., 2018)
- "GPT-3" (Brown et al., 2020)

**PINN:**
- Raissi et al., "Physics-informed neural networks" (2019)
- Karniadakis et al., "Physics-informed machine learning" (2021)
- Cuomo et al., "Scientific Machine Learning" (2022)

### ì½”ë“œ ì €ì¥ì†Œ

- [HuggingFace Transformers](https://github.com/huggingface/transformers)
- [Annotated Transformer](http://nlp.seas.harvard.edu/annotated-transformer/)
- [Physics-Informed Neural Networks](https://github.com/maziarraissi/PINNs)
- [DeepXDE Library](https://deepxde.readthedocs.io/)

### êµì¬

**Neural Networks:**
- *Deep Learning* by Goodfellow, Bengio, and Courville
- MIT 6.S191: Introduction to Deep Learning

**Computational Physics:**
- *Computational Physics* by Mark Newman
- *Statistical Mechanics* (Pathria)
- *Monte Carlo Methods* (Landau & Binder)

---

## ğŸ†˜ ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ì´ìŠˆ

**1. Import ì˜¤ë¥˜:**
```bash
uv pip install numpy matplotlib scipy tensorflow torch
```

**2. í•œê¸€ í°íŠ¸ ê¹¨ì§:**
- Windows: 'Malgun Gothic' ì„¤ì¹˜ í™•ì¸
- Mac: 'AppleGothic' ê¸°ë³¸ ì œê³µ
- Linux: 'Nanum Gothic' ì„¤ì¹˜

**3. Out of Memory:**
- ì‹œí€€ìŠ¤ ê¸¸ì´ ì¤„ì´ê¸°
- Batch size ê°ì†Œ
- ê²©ì í¬ê¸° ì¶•ì†Œ (Ising Model)
- PINN ë„¤íŠ¸ì›Œí¬ ë ˆì´ì–´ ê°ì†Œ

**4. ì‹¤í–‰ ì‹œê°„ ì˜¤ë˜ ê±¸ë¦¼:**
- Monte Carlo sweeps ìˆ˜ ì¤„ì´ê¸°
- PINN epoch ìˆ˜ ê°ì†Œ
- ìƒ˜í”Œ ìˆ˜ ê°ì†Œ
- GPU ì‚¬ìš© ê³ ë ¤

**5. GPU ì„¤ì • (ì„ íƒì‚¬í•­):**
```python
# TensorFlow
import tensorflow as tf
print(tf.config.list_physical_devices('GPU'))

# PyTorch
import torch
print(torch.cuda.is_available())
```

---

## ğŸ“ ë¼ì´ì„¼ìŠ¤ ë° ì¸ìš©

ì´ ì½”ë“œëŠ” êµìœ¡ ëª©ì ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.

**ì‚¬ìš© ì‹œ ì°¸ì¡°:**
- Week 1-7: Based on MIT 6.S191 materials
- Week 6: Based on "Attention Is All You Need" (Vaswani et al., 2017)
- Week 9-12: Based on computational physics textbooks
- Week 13-14: Based on PINN research papers

**GitHub ì €ì¥ì†Œ:**
```
https://github.com/BogKim2/AIandML
```

---

## ğŸ‘¨â€ğŸ« ê°•ì˜ì ë…¸íŠ¸

### ê°•ì˜ ì§„í–‰ íŒ

**Part I (Week 1-7):**
- ì´ë¡ ê³¼ ì½”ë“œ êµ¬í˜„ì„ ê· í˜•ìˆê²Œ ë‹¤ë£° ê²ƒ
- í•™ìƒë“¤ì´ ì§ì ‘ ì½”ë“œë¥¼ ìˆ˜ì •í•´ë³´ë„ë¡ ìœ ë„
- Attention ë©”ì»¤ë‹ˆì¦˜ì€ ì‹œê°í™”ë¥¼ í†µí•´ ì„¤ëª…

**Part II (Week 9-12):**
- LLMì„ í™œìš©í•œ "vibe coding" ì‹¤ìŠµ ê°•ì¡°
- ë¬¼ë¦¬ì  ì§ê´€ê³¼ ìˆ˜ì¹˜ ê²°ê³¼ ë¹„êµ
- ì‹œê°í™”ë¥¼ í†µí•œ ì´í•´ ê°•í™”

**Part III (Week 13-14):**
- PINNì€ ì–´ë ¤ìš´ ì£¼ì œì´ë¯€ë¡œ ì¶©ë¶„í•œ ì‹œê°„ ë°°ì •
- TensorFlowì™€ PyTorch ëª¨ë‘ ë‹¤ë£¨ë˜, í•™ìƒì´ ì„ íƒ ê°€ëŠ¥í•˜ë„ë¡
- ì „í†µì  ë°©ë²•ê³¼ì˜ ë¹„êµë¥¼ í†µí•´ PINNì˜ ì¥ì  ê°•ì¡°

---

## ğŸ“Š í”„ë¡œì íŠ¸ í†µê³„

### ì „ì²´ ì½”ë“œ êµ¬ì„±
- **ì´ ì£¼ì°¨**: 13ì£¼ (Week 8 ì œì™¸)
- **ì´ Python íŒŒì¼**: ì•½ 60ê°œ
- **ì´ ì‹œê°í™” ì¶œë ¥**: 200ê°œ ì´ìƒ
- **ì½”ë“œ ë¼ì¸ ìˆ˜**: ì•½ 15,000ì¤„

### ë‹¤ë£¨ëŠ” ë¬¼ë¦¬ ë¶„ì•¼
- ê³ ì „ ì—­í•™ (Week 4, 9)
- ì „ìê¸°í•™ (Week 10)
- ì–‘ìì—­í•™ (Week 11)
- í†µê³„ë¬¼ë¦¬ (Week 12)
- PINN ì‘ìš© (Week 13-14)

---

*ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: 2025-01-21*
*ë²„ì „: 2.0 (ì£¼ì°¨ë³„ ìˆœì°¨ ì •ë¦¬)*
